import streamlit as st
import os
from langchain.document_loaders import TextLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import Ollama
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
import tempfile

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="RAG çŸ¥è¯†é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ– session state
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'qa_chain' not in st.session_state:
    st.session_state.qa_chain = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

def load_documents(uploaded_files):
    """åŠ è½½ä¸Šä¼ çš„æ–‡æ¡£"""
    documents = []
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    with tempfile.TemporaryDirectory() as temp_dir:
        for uploaded_file in uploaded_files:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½æ–‡æ¡£
            if uploaded_file.name.endswith(('.txt', '.md')):
                loader = TextLoader(file_path, encoding='utf-8')
                documents.extend(loader.load())
    
    return documents

def create_vector_store(documents):
    """åˆ›å»ºå‘é‡æ•°æ®åº“"""
    # æ–‡æœ¬åˆ†å‰²
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )
    texts = text_splitter.split_documents(documents)
    
    # åˆ›å»ºåµŒå…¥æ¨¡å‹
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )
    
    # åˆ›å»ºå‘é‡æ•°æ®åº“
    vector_store = Chroma.from_documents(
        documents=texts,
        embedding=embeddings
    )
    
    return vector_store

def create_qa_chain(vector_store, llm_type="ollama"):
    """åˆ›å»ºé—®ç­”é“¾"""
    
    # åˆ›å»ºæ£€ç´¢å™¨
    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs={"k": 3}
    )
    
    # åˆ›å»ºæç¤ºæ¨¡æ¿
    prompt_template = """
    åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®åœ°è¯´"æˆ‘ä¸çŸ¥é“"ã€‚

    ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
    {context}

    é—®é¢˜ï¼š{question}

    å›ç­”ï¼š
    """
    
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "question"]
    )
    
    # é€‰æ‹©è¯­è¨€æ¨¡å‹
    if llm_type == "ollama":
        try:
            llm = Ollama(model="llama2")
        except:
            st.error("æ— æ³•è¿æ¥åˆ° Ollamaï¼Œè¯·ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ")
            return None
    else:
        st.error("æš‚æ—¶åªæ”¯æŒ Ollama æ¨¡å‹")
        return None
    
    # åˆ›å»ºé—®ç­”é“¾
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt},
        return_source_documents=True
    )
    
    return qa_chain

def main():
    st.title("ğŸ¤– RAG çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")
    st.markdown("---")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“ æ–‡æ¡£ä¸Šä¼ ")
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æ¡£æ–‡ä»¶",
            type=['txt', 'md'],
            accept_multiple_files=True,
            help="æ”¯æŒ .txt å’Œ .md æ ¼å¼çš„æ–‡ä»¶"
        )
        
        if uploaded_files:
            st.success(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            
            if st.button("ğŸ”„ å¤„ç†æ–‡æ¡£", type="primary"):
                with st.spinner("æ­£åœ¨å¤„ç†æ–‡æ¡£..."):
                    try:
                        # åŠ è½½æ–‡æ¡£
                        documents = load_documents(uploaded_files)
                        st.success(f"æˆåŠŸåŠ è½½ {len(documents)} ä¸ªæ–‡æ¡£")
                        
                        # åˆ›å»ºå‘é‡æ•°æ®åº“
                        vector_store = create_vector_store(documents)
                        st.session_state.vector_store = vector_store
                        st.success("å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸï¼")
                        
                        # åˆ›å»ºé—®ç­”é“¾
                        qa_chain = create_qa_chain(vector_store)
                        if qa_chain:
                            st.session_state.qa_chain = qa_chain
                            st.success("é—®ç­”ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
                        
                    except Exception as e:
                        st.error(f"å¤„ç†æ–‡æ¡£æ—¶å‡ºé”™ï¼š{str(e)}")
        
        st.markdown("---")
        
        # ç³»ç»Ÿè®¾ç½®
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        
        # æ¸…ç©ºå¯¹è¯å†å²
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
            st.session_state.chat_history = []
            st.success("å¯¹è¯å†å²å·²æ¸…ç©º")
        
        # é‡ç½®ç³»ç»Ÿ
        if st.button("ğŸ”„ é‡ç½®ç³»ç»Ÿ"):
            st.session_state.vector_store = None
            st.session_state.qa_chain = None
            st.session_state.chat_history = []
            st.success("ç³»ç»Ÿå·²é‡ç½®")
    
    # ä¸»ç•Œé¢
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ’¬ å¯¹è¯ç•Œé¢")
        
        # æ˜¾ç¤ºå¯¹è¯å†å²
        chat_container = st.container()
        with chat_container:
            for i, (question, answer) in enumerate(st.session_state.chat_history):
                st.markdown(f"**ğŸ™‹â€â™‚ï¸ ç”¨æˆ·ï¼š** {question}")
                st.markdown(f"**ğŸ¤– åŠ©æ‰‹ï¼š** {answer}")
                st.markdown("---")
        
        # é—®é¢˜è¾“å…¥
        if st.session_state.qa_chain:
            question = st.text_input(
                "è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š",
                placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨æƒ³é—®çš„é—®é¢˜...",
                key="question_input"
            )
            
            col_ask, col_clear = st.columns([3, 1])
            
            with col_ask:
                if st.button("ğŸš€ æé—®", type="primary", use_container_width=True):
                    if question:
                        with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                            try:
                                result = st.session_state.qa_chain({"query": question})
                                answer = result['result']
                                
                                # æ·»åŠ åˆ°å¯¹è¯å†å²
                                st.session_state.chat_history.append((question, answer))
                                
                                # é‡æ–°è¿è¡Œä»¥æ›´æ–°ç•Œé¢
                                st.rerun()
                                
                            except Exception as e:
                                st.error(f"å›ç­”é—®é¢˜æ—¶å‡ºé”™ï¼š{str(e)}")
                    else:
                        st.warning("è¯·è¾“å…¥é—®é¢˜")
        else:
            st.info("è¯·å…ˆä¸Šä¼ æ–‡æ¡£å¹¶å¤„ç†åå†å¼€å§‹æé—®")
    
    with col2:
        st.header("ğŸ“Š ç³»ç»ŸçŠ¶æ€")
        
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        if st.session_state.vector_store:
            st.success("âœ… å‘é‡æ•°æ®åº“å·²å°±ç»ª")
        else:
            st.warning("â³ å‘é‡æ•°æ®åº“æœªåˆå§‹åŒ–")
        
        if st.session_state.qa_chain:
            st.success("âœ… é—®ç­”ç³»ç»Ÿå·²å°±ç»ª")
        else:
            st.warning("â³ é—®ç­”ç³»ç»Ÿæœªåˆå§‹åŒ–")
        
        st.markdown(f"**å¯¹è¯è½®æ•°ï¼š** {len(st.session_state.chat_history)}")
        
        # ä½¿ç”¨è¯´æ˜
        st.markdown("---")
        st.header("ğŸ“ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. **ä¸Šä¼ æ–‡æ¡£**ï¼šåœ¨å·¦ä¾§ä¸Šä¼  .txt æˆ– .md æ ¼å¼çš„æ–‡æ¡£
        2. **å¤„ç†æ–‡æ¡£**ï¼šç‚¹å‡»"å¤„ç†æ–‡æ¡£"æŒ‰é’®åˆ›å»ºçŸ¥è¯†åº“
        3. **å¼€å§‹æé—®**ï¼šåœ¨å¯¹è¯ç•Œé¢è¾“å…¥é—®é¢˜å¹¶æé—®
        4. **æŸ¥çœ‹å›ç­”**ï¼šç³»ç»Ÿä¼šåŸºäºä¸Šä¼ çš„æ–‡æ¡£å›ç­”é—®é¢˜
        
        **æ³¨æ„äº‹é¡¹ï¼š**
        - ç¡®ä¿ Ollama æœåŠ¡æ­£åœ¨è¿è¡Œ
        - æ”¯æŒå¤šæ–‡æ¡£åŒæ—¶ä¸Šä¼ 
        - å¯ä»¥éšæ—¶æ¸…ç©ºå¯¹è¯å†å²æˆ–é‡ç½®ç³»ç»Ÿ
        """)

if __name__ == "__main__":
    main()
